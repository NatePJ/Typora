### `torch.nn`  介绍

- `torch.nn`  中  `nn`  代表  `Neural Network`的缩写
  - `torch.nn`  是对  `torch.nn.functional`  包装，更方便我们使用
- 基础模块简介
  - `Containers`  为神经网络定义一些骨架结构
  - `Convolution Layers`  卷积层
  - `Pooling layers`  石化层
  - `Padding Layers`  对输入的图片数据进行各种填充的方式
  - `Non-linear Activations `  非线性激活
  - `Normalization Layers`  正则化层

---



### 教学

> `torch.nn.Module`

- Base class for all neural network modules.*所有神经网络的类都需要继承  `torch.nn.Module`*

- 官方示例

  ```python
  import torch.nn as nn
  import torch.nn.functional as F
  
  class Model(nn.Module):
      def __init__(self):
          super(Model, self).__init__()
          self.conv1 = nn.Conv2d(1, 20, 5)
          self.conv2 = nn.Conv2d(20, 20, 5)
  
      def forward(self, x):
          x = F.relu(self.conv1(x))
          return F.relu(self.conv2(x))
  ```

  - 代码解析

    ```python
    重写 __init__()函数
    forward()函数 所有的子类都需要重写，神经网络中用于计算的函数
    
                    +------------+
    	input------>|  forward() |------>output
                    +------------+
                        神经网络
    self.conv1(x)	# x 先进行卷积层变换
    x = F.relu(self.conv1(x))	# 在卷积层变换后再进行一次非线性变换
    return F.relu(self.conv2(x))	# 在上述基础上再进行第二次卷积层变换与非线性变换并把结果输出
    ```

- 学习实例代码

  ```python
  import torch
  import torch.nn as nn
  
  class PjModule(nn.Module):
      def __init__(self):
          super().__init__()
  
      def forward(self, input):
          output = input + 1
          return output
  
  module = PjModule()
  # x = torch.tensor(1.0)
  output = module(1)
  print(output)
  ```

